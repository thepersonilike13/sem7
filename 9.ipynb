{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47747307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# âœ… Device setup\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using:\", device)\n",
    "\n",
    "# âœ… Simple transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# âœ… Tiny CIFAR-10 subset for quick testing\n",
    "testset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "test_subset, _ = torch.utils.data.random_split(testset, [1000, len(testset) - 1000])\n",
    "testloader = torch.utils.data.DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "# âœ… Load the quantization-ready MobileNetV2 model\n",
    "model_fp32 = models.quantization.mobilenet_v2(weights=\"DEFAULT\", quantize=False)\n",
    "model_fp32.eval()\n",
    "\n",
    "# âœ… Set quantization backend\n",
    "torch.backends.quantized.engine = \"fbgemm\"\n",
    "\n",
    "# âœ… Fuse model (now available)\n",
    "model_fp32.fuse_model()\n",
    "\n",
    "# âœ… Define quantization config\n",
    "model_fp32.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "\n",
    "# âœ… Prepare and calibrate\n",
    "model_prepared = torch.quantization.prepare(model_fp32)\n",
    "with torch.no_grad():\n",
    "    for imgs, _ in list(testloader)[:5]:\n",
    "        model_prepared(imgs)\n",
    "\n",
    "# âœ… Convert to quantized version\n",
    "model_int8 = torch.quantization.convert(model_prepared)\n",
    "print(\"âœ… Model quantized successfully!\")\n",
    "\n",
    "# âœ… Evaluate quickly\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in testloader:\n",
    "        outputs = model_int8(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "print(f\"ðŸŽ¯ Quantized Model Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
